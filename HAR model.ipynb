{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3AdbpZFCRR0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import pafy\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "from moviepy.editor import *\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pEI_v7HD1WV"
      },
      "outputs": [],
      "source": [
        "seed_constant = 23\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oQnKb7fbC2aq",
        "outputId": "bdd0f596-4406-48fc-b6c0-38c84113ea5f"
      },
      "outputs": [],
      "source": [
        "# Create a Matplotlib figure\n",
        "plt.figure(figsize = (30, 30))\n",
        "\n",
        "# Get Names of all classes in UCF50\n",
        "all_classes_names = os.listdir('UCF50')\n",
        "\n",
        "# Generate a random sample of images each time the cell runs\n",
        "random_range = random.sample(range(len(all_classes_names)), 20)\n",
        "\n",
        "# Iterating through all the random samples\n",
        "for counter, random_index in enumerate(random_range, 1):\n",
        "\n",
        "    # Getting Class Name using Random Index\n",
        "    selected_class_Name = all_classes_names[random_index]\n",
        "\n",
        "    # Getting a list of all the video files present in a Class Directory\n",
        "    video_files_names_list = os.listdir(f'UCF50/{selected_class_Name}')\n",
        "\n",
        "    # Randomly selecting a video file\n",
        "    selected_video_file_name = random.choice(video_files_names_list)\n",
        "\n",
        "    # Reading the Video File Using the Video Capture\n",
        "    video_reader = cv2.VideoCapture(f'UCF50/{selected_class_Name}/{selected_video_file_name}')\n",
        "    \n",
        "    # Reading The First Frame of the Video File\n",
        "    _, bgr_frame = video_reader.read()\n",
        "\n",
        "    # Closing the VideoCapture object and releasing all resources. \n",
        "    video_reader.release()\n",
        "\n",
        "    # Converting the BGR Frame to RGB Frame \n",
        "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Adding The Class Name Text on top of the Video Frame.\n",
        "    cv2.putText(rgb_frame, selected_class_Name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "    \n",
        "    # Assigning the Frame to a specific position of a subplot\n",
        "    plt.subplot(5, 4, counter)\n",
        "    plt.imshow(rgb_frame)\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gb4Fv7Ag-kwb"
      },
      "outputs": [],
      "source": [
        "image_height, image_width = 64, 64\n",
        "max_images_per_class = 8000\n",
        "\n",
        "dataset_directory = \"UCF50\"\n",
        "classes_list = [\"WalkingWithDog\", \"TaiChi\", \"Swing\", \"HorseRace\"]\n",
        "\n",
        "model_output_size = len(classes_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBu224OG-szz"
      },
      "outputs": [],
      "source": [
        "def frames_extraction(video_path):\n",
        "    # Empty List declared to store video frames\n",
        "    frames_list = []\n",
        "    \n",
        "    # Reading the Video File Using the VideoCapture\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Iterating through Video Frames\n",
        "    while True:\n",
        "\n",
        "        # Reading a frame from the video file \n",
        "        success, frame = video_reader.read() \n",
        "\n",
        "        # If Video frame was not successfully read then break the loop\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed Dimensions\n",
        "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
        "        \n",
        "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
        "        normalized_frame = resized_frame / 255\n",
        "        \n",
        "        # Appending the normalized frame into the frames list\n",
        "        frames_list.append(normalized_frame)\n",
        "    \n",
        "    # Closing the VideoCapture object and releasing all resources. \n",
        "    video_reader.release()\n",
        "\n",
        "    # returning the frames list \n",
        "    return frames_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6MLp9PpDJ4-"
      },
      "outputs": [],
      "source": [
        "def create_dataset():\n",
        "\n",
        "    # Declaring Empty Lists to store the features and labels values.\n",
        "    temp_features = [] \n",
        "    features = []\n",
        "    labels = []\n",
        "    \n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(classes_list):\n",
        "        print(f'Extracting Data of Class: {class_name}')\n",
        "        \n",
        "        # Getting the list of video files present in the specific class name directory\n",
        "        files_list = os.listdir(os.path.join(dataset_directory, class_name))\n",
        "\n",
        "        # Iterating through all the files present in the files list\n",
        "        for file_name in files_list:\n",
        "\n",
        "            # Construct the complete video path\n",
        "            video_file_path = os.path.join(dataset_directory, class_name, file_name)\n",
        "\n",
        "            # Calling the frame_extraction method for every video file path\n",
        "            frames = frames_extraction(video_file_path)\n",
        "\n",
        "            # Appending the frames to a temporary list.\n",
        "            temp_features.extend(frames)\n",
        "        \n",
        "        # Adding randomly selected frames to the features list\n",
        "        features.extend(random.sample(temp_features, max_images_per_class))\n",
        "\n",
        "        # Adding Fixed number of labels to the labels list\n",
        "        labels.extend([class_index] * max_images_per_class)\n",
        "        \n",
        "        # Emptying the temp_features list so it can be reused to store all frames of the next class.\n",
        "        temp_features.clear()\n",
        "\n",
        "    # Converting the features and labels lists to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    labels = np.array(labels)  \n",
        "\n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckAYgSriJN_R",
        "outputId": "b787e183-66af-4fdc-b494-49c2fdbcee59"
      },
      "outputs": [],
      "source": [
        "features, labels = create_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goRGrc8_0Usb"
      },
      "source": [
        "Now we will convert class labels to one hot encoded vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfcpuV6_Bd_T"
      },
      "outputs": [],
      "source": [
        "# Using Keras's to_categorical method to convert labels into one-hot-encoded vectors\n",
        "one_hot_encoded_labels = to_categorical(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhkQjq1JJSO2"
      },
      "outputs": [],
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.2, shuffle = True, random_state = seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8cDSpfXJXwx",
        "outputId": "7a93fc19-2943-4272-e2f8-f4169fab5ce8"
      },
      "outputs": [],
      "source": [
        "# Let's create a function that will construct our model\n",
        "def create_model():\n",
        "\n",
        "    # We will use a Sequential model for model construction\n",
        "    model = Sequential()\n",
        "\n",
        "    # Defining The Model Architecture\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (image_height, image_width, 3)))\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(256, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(model_output_size, activation = 'softmax'))\n",
        "\n",
        "    # Printing the models summary\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Calling the create_model method\n",
        "model = create_model()\n",
        "\n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "id": "hbSK_rKUK-xQ",
        "outputId": "c47c49e7-0f9d-4117-deab-0db8c9b71f16"
      },
      "outputs": [],
      "source": [
        "plot_model(model, to_file = 'model_structure_plot.png', show_shapes = True, show_layer_names = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju_Mq42yQhqN",
        "outputId": "26e8ce7e-30f3-49f2-dcc3-3d3048a2ec83"
      },
      "outputs": [],
      "source": [
        "# Adding the Early Stopping Callback to the model which will continuously monitor the validation loss metric for every epoch.\n",
        "# If the models validation loss does not decrease after 15 consecutive epochs, the training will be stopped and the weight which reported the lowest validation loss will be retored in the model.\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "# Adding loss, optimizer and metrics values to the model.\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
        "\n",
        "# Start Training\n",
        "model_training_history = model.fit(x = features_train, y = labels_train, epochs = 50, batch_size = 4 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "74tGjokkmSHR",
        "outputId": "4ce77b8e-4ad5-419f-eaf4-f55774fd82a5"
      },
      "outputs": [],
      "source": [
        "model_evaluation_history = model.evaluate(features_test, labels_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGglb-k867iK"
      },
      "source": [
        "### **Save Your Model**\n",
        "You should now save your model for future runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GLfnP_czYudN"
      },
      "outputs": [],
      "source": [
        "# Creating a useful name for our model, incase you're saving multiple models (OPTIONAL)\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        "model_name = f'Model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        "\n",
        "# Saving your Model\n",
        "model.save(model_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Introduction to Video Classification & Human Activity Recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
